import os
# é™é»˜ tokenizer å¹¶è¡Œåˆ†å‰å‘Šè­¦
os.environ["TOKENIZERS_PARALLELISM"] = "false"
import argparse
import json
import time
from pathlib import Path
import shutil
import csv # Added for saving training log

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight

from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    TrainerCallback,
    EarlyStoppingCallback,
    set_seed
)

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
import seaborn as sns

# é…ç½®ï¼ˆä¸ notebooks æ€è·¯å¯¹é½ï¼Œä½†ä¿ç•™ BERT/DistilBERTï¼‰
MODEL_PATH = "./models/SecureBERT" 
PROCESSED_DATA_BASE_DIR = "./processed_data"  # é¢„å¤„ç†æ•°æ®åŸºç¡€ç›®å½•
# æ ¹æ® mode è‡ªåŠ¨é€‰æ‹©å­ç›®å½•ï¼šbinary -> bert/binary, multiclass -> bert/multiclass
OUTPUT_DIR_BINARY = "./models/securebert-finetuned"  # äºŒåˆ†ç±»å¾®è°ƒè¾“å‡º
OUTPUT_DIR_MULTICLASS = "./models/securebert-finetuned-multiclass"  # å¤šåˆ†ç±»å¾®è°ƒè¾“å‡º
# è®­ç»ƒæ¨¡å¼ï¼šbinary æˆ– multiclassï¼ˆä½œä¸ºä¿¡æ¯æç¤ºä¸ä¸€è‡´æ€§æ ¡éªŒï¼‰
DEFAULT_MODE = "binary"
DEFAULT_DATASET = "NF-UNSW-NB15-v3"  # é»˜è®¤æ•°æ®é›†åç§°
NUM_EPOCHS = 6
RANDOM_SEED = 42

# --- è°ƒè¯•/é‡‡æ ·é…ç½® ---
# å°† DEBUG_SAMPLE_RATIO è®¾ä¸º < 1.0 å³å¯åªç”¨éƒ¨åˆ†æ ·æœ¬ï¼Œä¾¿äºå¿«é€Ÿè°ƒè¯•è·‘é€šæµç¨‹ã€‚
# æ­£å¼å®éªŒæ—¶ï¼Œè¯·æ”¹å› 1.0ã€‚
DEBUG_SAMPLE_RATIO = 0.4  # ä¾‹å¦‚ 0.1 è¡¨ç¤ºåªç”¨ 10% çš„æ ·æœ¬


def get_bert_dir(dataset_name: str, mode: str) -> str:
    """æ ¹æ®æ•°æ®é›†åç§°å’Œè®­ç»ƒæ¨¡å¼è¿”å›å¯¹åº”çš„æ•°æ®ç›®å½•"""
    return os.path.join(PROCESSED_DATA_BASE_DIR, dataset_name, 'bert', mode)


def get_output_dir(mode: str) -> str:
    """æ ¹æ®è®­ç»ƒæ¨¡å¼è¿”å›å¯¹åº”çš„è¾“å‡ºç›®å½•"""
    if mode == 'binary':
        return OUTPUT_DIR_BINARY
    else:
        return OUTPUT_DIR_MULTICLASS

class PacketDataset(Dataset):
    """å°†é¢„å¤„ç†åçš„ 'text' æ‹¼æ¥ç‰¹å¾é€å…¥ BERT çš„æ•°æ®é›†å°è£…"""
    def __init__(self, tokenizer, texts, labels, max_length=512):
        self.tokenizer = tokenizer
        self.texts = texts
        self.labels = labels
        self.max_length = max_length
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])
        enc = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        return {
            'input_ids': enc['input_ids'].squeeze(0),
            'attention_mask': enc['attention_mask'].squeeze(0),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class DetailedLoggingCallback(TrainerCallback):
    """è®°å½•æ¯ä¸ª epoch çš„è®­ç»ƒä¸éªŒè¯åº¦é‡ï¼Œä¿è¯æŒ‡æ ‡æŒ‰è½®æ¬¡å˜åŒ–"""
    def __init__(self):
        self.epoch_start_time = None
        self.current_epoch = 0
        self.epochs = []
        self.train_losses = []
        self.val_losses = []
        self.val_accs = []
        self.val_f1s = []
    
    def on_train_begin(self, args, state, control, **kwargs):
        print("\n" + "="*80)
        print("å¼€å§‹è®­ç»ƒ")
        print("="*80)
        print(f"é…ç½®: epochs={args.num_train_epochs} | batch={args.per_device_train_batch_size} | lr={args.learning_rate} | scheduler={args.lr_scheduler_type}")
        print("-" * 80)
    
    def on_epoch_begin(self, args, state, control, **kwargs):
        # é¿å… int(state.epoch)==0 å¯¼è‡´è¿ç»­æ‰“å° 0ï¼›ä½¿ç”¨æœ¬åœ°è®¡æ•°å™¨ç»Ÿä¸€é€’å¢
        self.current_epoch += 1
        self.epoch_start_time = time.time()
        print(f"\nğŸ“ Epoch {self.current_epoch} å¼€å§‹...")
    def on_log(self, args, state, control, logs=None, **kwargs):
        # é™ä½æ—¥å¿—é¢‘ç‡ï¼šä¸åœ¨æ¯ä¸ª step æ‰“å°
        return
    
    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics and self.epoch_start_time:
            duration = time.time() - self.epoch_start_time
            val_loss = float(metrics.get('eval_loss', 0))
            val_acc = float(metrics.get('eval_accuracy', 0))
            val_f1 = float(metrics.get('eval_f1', 0))
            val_prec = float(metrics.get('eval_precision', 0))
            val_rec = float(metrics.get('eval_recall', 0))
            # ä» state.log_history æ‰¾æœ€è¿‘çš„è®­ç»ƒ loss
            train_loss = next((float(log['loss']) for log in reversed(state.log_history) if 'loss' in log), None)
            if train_loss is None:
                train_loss = float('nan')
            self.epochs.append(self.current_epoch)
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_accs.append(val_acc)
            self.val_f1s.append(val_f1)
            print(f"  Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}")
            print(f"  Precision: {val_prec:.4f} | Recall: {val_rec:.4f}")
            print(f"  â±ï¸  Duration: {duration:.1f}s")
    
    def on_train_end(self, args, state, control, **kwargs):
        best_val_loss = min(self.val_losses) if self.val_losses else float('nan')
        best_val_f1 = max(self.val_f1s) if self.val_f1s else float('nan')
        print("\n" + "="*80)
        print(f"âœ“ è®­ç»ƒå®Œæˆ | æœ€ä½³: Val Loss={best_val_loss:.4f}, F1={best_val_f1:.4f}")
        print("="*80)
        
        # New: Save to CSV
        csv_path = os.path.join(args.output_dir, 'training_log.csv')
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['epoch', 'train_loss', 'val_loss', 'val_acc', 'val_f1']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            for i in range(len(self.epochs)):
                writer.writerow({
                    'epoch': self.epochs[i],
                    'train_loss': self.train_losses[i],
                    'val_loss': self.val_losses[i],
                    'val_acc': self.val_accs[i],
                    'val_f1': self.val_f1s[i]
                })
        print(f"âœ… è®­ç»ƒæ—¥å¿—å·²ä¿å­˜è‡³: {csv_path}")
    
    def get_plot_data(self):
        return {
            'epochs': self.epochs,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'val_accs': self.val_accs,
            'val_f1s': self.val_f1s
        }
class FocalLoss(nn.Module):
    """å¤šåˆ†ç±» Focal Lossã€‚
    å‚æ•°:
      gamma: èšç„¦å‚æ•°ï¼Œè¶Šå¤§è¶Šå…³æ³¨éš¾æ ·æœ¬ï¼ˆé»˜è®¤ 2.0ï¼‰
      alpha: å¯é€‰çš„æ¯ç±»æƒé‡å¼ é‡ï¼Œshape=[num_labels]ï¼›ä¸º None æ—¶ä¸ä½¿ç”¨ç±»æƒé‡
    """
    def __init__(self, gamma: float = 2.0, alpha: torch.Tensor = None, reduction: str = 'mean'):
        super().__init__()
        self.gamma = float(gamma)
        self.reduction = reduction
        # ä½¿ç”¨ register_buffer ç¡®ä¿ alpha éšæ¨¡å‹è‡ªåŠ¨è¿ç§»åˆ°æ­£ç¡®è®¾å¤‡ï¼ˆCPU/GPUï¼‰
        if alpha is not None:
            self.register_buffer('alpha', alpha)
        else:
            self.alpha = None

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        ce = nn.CrossEntropyLoss(reduction='none')(logits, targets)
        pt = torch.exp(-ce)  # é¢„æµ‹ä¸ºçœŸç±»çš„æ¦‚ç‡
        focal = ((1 - pt) ** self.gamma) * ce
        if self.alpha is not None:
            # alpha é€šè¿‡ register_buffer æ³¨å†Œï¼Œéšæ¨¡å‹è‡ªåŠ¨è¿ç§»è®¾å¤‡
            # æ­¤å¤„ä»…åšç´¢å¼•å–æƒé‡ï¼Œä¸ä¿®æ”¹ self.alpha
            alpha_weight = self.alpha[targets]
            focal = alpha_weight * focal
        if self.reduction == 'mean':
            return focal.mean()
        if self.reduction == 'sum':
            return focal.sum()
        return focal


def _ensure_int_labels(series: pd.Series) -> np.ndarray:
    """å°† label åˆ—è½¬ä¸º int numpy æ•°ç»„ï¼ˆè‹¥å­˜åœ¨è„æ•°æ®åˆ™å°½é‡å®¹é”™ï¼‰ã€‚"""
    # æ³¨æ„ï¼šè®­ç»ƒ/è¯„ä¼°éƒ½ä¾èµ– label ä¸ºä» 0 å¼€å§‹çš„éè´Ÿæ•´æ•°
    return pd.to_numeric(series, errors='coerce').fillna(0).astype(int).values


def _infer_num_labels_from_labels(all_labels: np.ndarray) -> int:
    """æ›´ç¨³å¥åœ°æ¨æ–­ num_labelsï¼š
    - è‹¥æ ‡ç­¾æ˜¯éè´Ÿæ•´æ•°ï¼šç”¨ max+1ï¼ˆå³ä½¿ä¸­é—´æœ‰ç¼ºå¤± id ä¹Ÿä¸ä¼šç»´åº¦ä¸åŒ¹é…ï¼‰
    - å¦åˆ™ï¼šé€€åŒ–ä¸º unique æ•°é‡
    """
    if all_labels.size == 0:
        return 0
    try:
        min_v = int(np.min(all_labels))
        max_v = int(np.max(all_labels))
        if min_v >= 0:
            return int(max_v + 1)
    except Exception:
        pass
    return int(np.unique(all_labels).size)


def load_bert_datasets(bert_dir: str, mode: str = 'binary'):
    """åŠ è½½ processed_data/bert ä¸‹çš„ train/val/test_fusion.csvï¼Œè¿”å› DataFrame åŠåŸºæœ¬ç»Ÿè®¡ã€‚

    å‚æ•°:
      bert_dir: processed_data/bert ç›®å½•
      mode: 'binary' æˆ– 'multiclass'

    çº¦å®š:
      - binary: ç»Ÿä¸€æ˜ å°„ä¸º 0=æ­£å¸¸, 1=æ”»å‡»ï¼ˆä»»ä½•é0éƒ½è§†ä¸ºæ”»å‡»ï¼‰
      - multiclass: ä¿ç•™åŸå§‹å¤šç±» labelï¼ˆåº”ä¸ºä» 0 å¼€å§‹çš„æ•´æ•° idï¼‰
    """
    def read_csv(path):
        try:
            df = pd.read_csv(path)
            print(f"  âœ“ {path}: {len(df)} è¡Œ")
            return df
        except Exception as e:
            print(f"  âœ— {path}: {e}")
            return None
    print(f"\nåŠ è½½æ•°æ®é›†...")
    train_df = read_csv(f"{bert_dir}/train_fusion.csv")
    val_df = read_csv(f"{bert_dir}/val_fusion.csv")
    test_df = read_csv(f"{bert_dir}/test_fusion.csv")
    if train_df is None or val_df is None or test_df is None:
        raise ValueError("æ•°æ®é›†åŠ è½½å¤±è´¥")
    
    # è°ƒè¯•æ¨¡å¼ï¼šä»…ä½¿ç”¨éƒ¨åˆ†æ ·æœ¬ï¼ˆåˆ†å±‚é‡‡æ ·ï¼Œä¿æŒç±»åˆ«æ¯”ä¾‹ï¼‰
    if 0 < DEBUG_SAMPLE_RATIO < 1.0:
        n_train_orig = len(train_df)
        n_val_orig = len(val_df)
        n_test_orig = len(test_df)
        
        def stratified_sample(df, frac, label_col='label'):
            """åˆ†å±‚é‡‡æ ·ï¼šä»æ¯ä¸ªç±»åˆ«ä¸­æŒ‰ç›¸åŒæ¯”ä¾‹æŠ½å–æ ·æœ¬"""
            sampled_dfs = []
            for label_val in df[label_col].unique():
                label_subset = df[df[label_col] == label_val]
                n_sample = max(1, int(len(label_subset) * frac))  # è‡³å°‘ä¿ç•™1ä¸ªæ ·æœ¬
                sampled_dfs.append(
                    label_subset.sample(n=n_sample, random_state=RANDOM_SEED)
                )
            return pd.concat(sampled_dfs, axis=0).sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)
        
        train_df = stratified_sample(train_df, DEBUG_SAMPLE_RATIO)
        val_df = stratified_sample(val_df, DEBUG_SAMPLE_RATIO)
        test_df = stratified_sample(test_df, DEBUG_SAMPLE_RATIO)
        
        print(f"\nâš ï¸  è°ƒè¯•æ¨¡å¼å¯ç”¨ (DEBUG_SAMPLE_RATIO={DEBUG_SAMPLE_RATIO}, åˆ†å±‚é‡‡æ ·):")
        print(f"  è®­ç»ƒé›†: {n_train_orig} -> {len(train_df)}")
        print(f"  éªŒè¯é›†: {n_val_orig} -> {len(val_df)}")
        print(f"  æµ‹è¯•é›†: {n_test_orig} -> {len(test_df)}")
    for df, name in [(train_df, 'train'), (val_df, 'val'), (test_df, 'test')]:
        if not all(col in df.columns for col in ['text', 'label']):
            raise ValueError(f"{name}.csv ç¼ºå°‘å¿…éœ€çš„åˆ—: ['text','label']")
    # ç»Ÿä¸€æ¸…æ´— label ä¸º int
    train_labels_raw = _ensure_int_labels(train_df['label'])
    val_labels_raw = _ensure_int_labels(val_df['label'])
    test_labels_raw = _ensure_int_labels(test_df['label'])

    if mode == 'binary':
        # äºŒåˆ†ç±»ï¼šä»»ä½•é0éƒ½è§†ä¸ºæ”»å‡»ç±» 1
        train_labels = np.where(train_labels_raw == 0, 0, 1)
        val_labels = np.where(val_labels_raw == 0, 0, 1)
        test_labels = np.where(test_labels_raw == 0, 0, 1)

        # è¦†å†™ DataFrameï¼Œä¿è¯åç»­ dataset / report å£å¾„ä¸€è‡´
        train_df = train_df.copy()
        val_df = val_df.copy()
        test_df = test_df.copy()
        train_df['label'] = train_labels
        val_df['label'] = val_labels
        test_df['label'] = test_labels

        label_counts = dict(zip(*np.unique(train_labels, return_counts=True)))
        print(f"\nè®­ç»ƒé›†ç»Ÿè®¡ (äºŒåˆ†ç±»æ¨¡å¼):")
        print(f"  æ€»æ ·æœ¬æ•°: {len(train_df)}")
        print(f"  ç±»åˆ«æ•°: 2 (0=æ­£å¸¸, 1=æ”»å‡»[é0])")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {label_counts}")

        # è‹¥åŸå§‹æ ‡ç­¾ä¸æ˜¯ {0,1}ï¼Œæ˜ç¡®æç¤ºç”¨æˆ·å½“å‰ CSV å®é™…ä¸Šæ¥è‡ªå¤šåˆ†ç±»é¢„å¤„ç†
        raw_unique = np.unique(train_labels_raw)
        if raw_unique.size > 2 or (raw_unique.size == 2 and not set(raw_unique.tolist()).issubset({0, 1})):
            print(f"  æç¤º: ä½ çš„ CSV åŸå§‹ label å»é‡åä¸º {raw_unique.tolist()}ï¼Œå·²åœ¨äºŒåˆ†ç±»æ¨¡å¼ä¸‹æ˜ å°„ä¸º 0/1ã€‚")
    else:
        # å¤šåˆ†ç±»ï¼šä¿ç•™åŸå§‹æ ‡ç­¾
        train_labels = train_labels_raw
        val_labels = val_labels_raw
        test_labels = test_labels_raw

        label_counts = dict(zip(*np.unique(train_labels, return_counts=True)))
        unique_labels = np.unique(train_labels)
        print(f"\nè®­ç»ƒé›†ç»Ÿè®¡ (å¤šåˆ†ç±»æ¨¡å¼):")
        print(f"  æ€»æ ·æœ¬æ•°: {len(train_df)}")
        print(f"  ç±»åˆ«æ•°: {len(unique_labels)}")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {label_counts}")
    if len(label_counts) > 0:
        max_count = max(label_counts.values())
        min_count = min(label_counts.values())
        if min_count > 0:
            print(f"  ä¸å¹³è¡¡åº¦: {max_count}/{min_count} = {max_count/min_count:.1f}x")
    # num_labelsï¼šbinary å›ºå®šä¸º 2ï¼›multiclass ç”¨ max+1 é˜²æ­¢æ ‡ç­¾ä¸è¿ç»­
    all_labels = np.concatenate([train_labels, val_labels, test_labels], axis=0)
    inferred_num_labels = 2 if mode == 'binary' else _infer_num_labels_from_labels(all_labels)

    return {
        # åŸå§‹ DataFrameï¼Œä¾¿äºåç»­è®¿é—®ä¼šè¯çº§å‰ç¼€ç‰¹å¾ç­‰æ•°å€¼åˆ—
        'train_df': train_df,
        'val_df': val_df,
        'test_df': test_df,
        # å…¼å®¹åŸæœ‰è°ƒç”¨æ–¹å¼çš„ tuple
        'train': (train_df['text'].values, train_labels),
        'val': (val_df['text'].values, val_labels),
        'test': (test_df['text'].values, test_labels),
        'num_labels': int(inferred_num_labels),
        'label_counts': label_counts
    }


def compute_class_weights(labels, num_labels, power):
    """ä½¿ç”¨ sklearn çš„ balanced ç­–ç•¥å¹¶è¿›è¡Œå¹‚å¹³æ»‘ï¼Œè¿”å›é•¿åº¦=num_labels çš„æƒé‡å¼ é‡"""
    unique_labels = np.unique(labels)
    base_weights = compute_class_weight(class_weight='balanced', classes=unique_labels, y=labels)
    smoothed = np.power(base_weights, power)
    smoothed = smoothed / smoothed.mean() if smoothed.mean() > 0 else smoothed
    weights = np.ones(num_labels, dtype=np.float32)
    for label, w in zip(unique_labels, smoothed):
        if 0 <= int(label) < num_labels:
            weights[int(label)] = float(w)
    print(f"\nç±»åˆ«æƒé‡ (å¹³æ»‘ç³»æ•°={power}): èŒƒå›´[{weights.min():.4f},{weights.max():.4f}] æ¯”ä¾‹{(weights.max()/max(weights.min(),1e-6)):.2f}x")
    return torch.tensor(weights, dtype=torch.float32)


def _format_session_stat_value(v):
    """å°†ä¼šè¯çº§æ•°å€¼ç‰¹å¾æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œä¾›ä¼ª token ä½¿ç”¨ã€‚"""
    try:
        fv = float(v)
        if abs(fv - round(fv)) < 1e-6:
            return str(int(round(fv)))
        return f"{fv:.4f}"
    except Exception:
        return str(v)


def build_text_with_session_tokens(df: pd.DataFrame, session_cols, base_text_col: str = 'text', sep_token: str = " </s> "):
    """
    å°†æ•°å€¼å‹ä¼šè¯å‰ç¼€ç‰¹å¾ç¼–ç ä¸ºä¼ª tokenï¼Œå¹¶ä¸åŸå§‹æµçº§æ–‡æœ¬æ‹¼æ¥ã€‚
    ç¤ºä¾‹ï¼š
      åŸ text: "1 2 3 ..."
      ä¼šè¯ç‰¹å¾: SESS_FLOW_COUNT=10, SESS_TOTAL_BYTES=1234
      æ‹¼æ¥å: "1 2 3 ... [SEP] SESS_FLOW_COUNT=10 SESS_TOTAL_BYTES=1234"
    """
    if not session_cols:
        return df[base_text_col].astype(str).values

    df_local = df.copy()
    df_local[session_cols] = df_local[session_cols].fillna(0)

    def _row_to_session_str(row):
        parts = []
        for col in session_cols:
            if col in row:
                parts.append(f"{col}={_format_session_stat_value(row[col])}")
        return " ".join(parts)

    session_strings = df_local.apply(_row_to_session_str, axis=1)
    # ä½¿ç”¨ä¼ å…¥çš„ sep_token ä½œä¸ºåˆ†éš”ç¬¦
    combined = df_local[base_text_col].astype(str) + sep_token + session_strings
    return combined.values


def train_roberta(model_path: str, bert_dir: str, output_dir: str, num_epochs: int,
                     mode: str = DEFAULT_MODE, dataset_name: str = DEFAULT_DATASET,
                     use_session_tokens: bool = True, loss_type: str = 'focal'):
    """
    é’ˆå¯¹ SecureBERT 2.0 (RoBERTaæ¶æ„) ä¿®æ­£åçš„å¾®è°ƒå‡½æ•°
    """
    set_seed(RANDOM_SEED)
    
    # --- 1. è·¯å¾„ä¸è®¾å¤‡æ£€æŸ¥ ---
    if not os.path.exists(model_path):
        raise ValueError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}ã€‚è¯·ç¡®ä¿ä¸‹è½½äº†å®Œæ•´çš„ SecureBERT æ–‡ä»¶(åŒ…å« config.json, pytorch_model.bin, vocab.json, merges.txt)")
    
    actual_bert_dir = bert_dir if bert_dir else get_bert_dir(dataset_name, mode)
    if not os.path.exists(actual_bert_dir):
        raise ValueError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {actual_bert_dir}ã€‚è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ã€‚")
        
    os.makedirs(output_dir, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ | æ¨¡å¼: {mode} | è®¾å¤‡: {device}")
    print(f"ğŸ“‚ æ¨¡å‹æ¥æº: {model_path}")

    # --- 2. åŠ è½½æ•°æ® ---
    data = load_bert_datasets(actual_bert_dir, mode=mode)
    train_df, val_df, test_df = data['train_df'], data['val_df'], data['test_df']
    num_labels = data['num_labels']
    
    # ç¡®ä¿æ ‡ç­¾ä¸ºæ•´æ•°
    train_labels = _ensure_int_labels(train_df['label'])
    val_labels = _ensure_int_labels(val_df['label'])
    test_labels = _ensure_int_labels(test_df['label'])
    
    # äºŒåˆ†ç±»æ¨¡å¼ä¸‹çš„å¼ºåˆ¶æ¸…æ´—
    if mode == 'binary':
        train_labels = np.where(train_labels == 0, 0, 1)
        val_labels = np.where(val_labels == 0, 0, 1)
        test_labels = np.where(test_labels == 0, 0, 1)

    # --- 3. Tokenizer åŠ è½½ (é’ˆå¯¹ SecureBERT/RoBERTa ä¿®æ­£) ---
    print("\nğŸ”„ åŠ è½½ Tokenizer (SecureBERT/RoBERTa)...")
    try:
        # add_prefix_space=True å¯¹ RoBERTa åˆ†è¯å¾ˆé‡è¦
        tokenizer = AutoTokenizer.from_pretrained(model_path, add_prefix_space=True)
    except Exception as e:
        print(f"âš ï¸ å¸¸è§„åŠ è½½å¤±è´¥ï¼Œå°è¯•ä¸å¸¦ add_prefix_space: {e}")
        tokenizer = AutoTokenizer.from_pretrained(model_path)

    # ã€å…³é”®ä¿®æ­£ã€‘ä¸è¦å¼ºåˆ¶å°† pad_token è®¾ä¸º eos_tokenï¼
    # RoBERTa é»˜è®¤æœ‰ pad_token (id=1) å’Œ eos_token (id=2)ã€‚
    # åªæœ‰å½“ pad_token çœŸçš„ä¸å­˜åœ¨æ—¶æ‰è®¾ç½®ã€‚
    if tokenizer.pad_token is None:
        print("âš ï¸ æ£€æµ‹åˆ° pad_token ä¸ºç©ºï¼Œæ‰‹åŠ¨è®¾ç½®ä¸º eos_token (ä»…é’ˆå¯¹éæ ‡å‡†æ¨¡å‹)")
        tokenizer.pad_token = tokenizer.eos_token
    else:
        print(f"âœ… Tokenizer çŠ¶æ€æ­£å¸¸: PAD_ID={tokenizer.pad_token_id}, EOS_ID={tokenizer.eos_token_id}")

    # è·å–åˆ†éš”ç¬¦ (RoBERTa é»˜è®¤ä¸º </s>)
    sep_token_str = f" {tokenizer.sep_token} "

    # --- 4. ç‰¹å¾å·¥ç¨‹ (ä¼šè¯ Token æ‹¼æ¥) ---
    # è¯»å–ç‰¹å¾é…ç½®ï¼ˆä»æ•°æ®é›†ç›®å½•è¯»å–ï¼‰
    feature_cfg_path = Path(PROCESSED_DATA_BASE_DIR) / dataset_name / 'feature_columns.json'
    session_stat_cols = []
    if feature_cfg_path.exists():
        try:
            with open(feature_cfg_path, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
            session_stat_cols = cfg.get('session_stat_features', [])
        except Exception:
            pass
    
    if use_session_tokens and session_stat_cols:
        print(f"âœ¨ å¯ç”¨ä¼šè¯ç‰¹å¾æ‹¼æ¥ (ç‰¹å¾æ•°: {len(session_stat_cols)})")
        train_texts = build_text_with_session_tokens(train_df, session_stat_cols, sep_token=sep_token_str)
        val_texts = build_text_with_session_tokens(val_df, session_stat_cols, sep_token=sep_token_str)
        test_texts = build_text_with_session_tokens(test_df, session_stat_cols, sep_token=sep_token_str)
    else:
        print("â„¹ï¸ ä»…ä½¿ç”¨åŸå§‹æ–‡æœ¬ (ä¸æ‹¼æ¥ä¼šè¯ç‰¹å¾)")
        train_texts = train_df['text'].astype(str).values
        val_texts = val_df['text'].astype(str).values
        test_texts = test_df['text'].astype(str).values

    # --- 5. æ¨¡å‹åŠ è½½ (Head Replacement) ---
    print(f"\nğŸ—ï¸ åŠ è½½æ¨¡å‹ (num_labels={num_labels})...")
    model = AutoModelForSequenceClassification.from_pretrained(
        model_path,
        num_labels=int(num_labels),
        ignore_mismatched_sizes=True  # å…è®¸æ›¿æ¢ Head
    )
    
    # åŒæ­¥ Tokenizer å’Œ Model çš„ Pad ID
    model.config.pad_token_id = tokenizer.pad_token_id
    model.to(device)

    # --- 6. æ•°æ®é›†æ„å»º ---
    train_dataset = PacketDataset(tokenizer, train_texts, train_labels)
    val_dataset = PacketDataset(tokenizer, val_texts, val_labels)
    test_dataset = PacketDataset(tokenizer, test_texts, test_labels)

    # --- 7. ç±»åˆ«å¹³è¡¡é‡‡æ ·å™¨ (WeightedRandomSampler) ---
    train_label_tensor = torch.tensor(train_labels, dtype=torch.long)
    # è®¡ç®—ç±»åˆ«è®¡æ•°ï¼Œé˜²æ­¢ç´¢å¼•è¶Šç•Œ
    class_counts = torch.bincount(train_label_tensor, minlength=int(num_labels)).float()
    class_counts = torch.clamp(class_counts, min=1.0) # é˜²æ­¢é™¤é›¶
    class_weights_for_sampler = 1.0 / class_counts
    
    # ç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„æƒé‡
    sample_weights = class_weights_for_sampler[train_label_tensor]
    
    train_sampler = WeightedRandomSampler(
        weights=sample_weights,
        num_samples=len(sample_weights),
        replacement=True
    )

    # --- 8. æŸå¤±å‡½æ•°å®šä¹‰ ---
    focal_gamma = 2.0
    if loss_type == 'ce':
        loss_fn = nn.CrossEntropyLoss().to(device)
    elif loss_type == 'focal':
        loss_fn = FocalLoss(gamma=focal_gamma, alpha=None).to(device)
    elif loss_type == 'focal_weighted':
        # è®¡ç®— Loss ä¸­çš„ç±»åˆ«æƒé‡ (åŒºåˆ«äº Sampler)
        class_weights = compute_class_weights(train_labels, num_labels, power=0.25)
        loss_fn = FocalLoss(gamma=focal_gamma, alpha=class_weights).to(device)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ loss_type: {loss_type}")

    # --- 9. Trainer å®šä¹‰ (ä¿æŒåŸæœ‰ CustomLossTrainer é€»è¾‘) ---
    class CustomLossTrainer(Trainer):
        def __init__(self, *args, loss_fn=None, train_sampler=None, **kwargs):
            super().__init__(*args, **kwargs)
            self.loss_fn = loss_fn
            self.train_sampler = train_sampler

        def get_train_dataloader(self):
            if self.train_sampler is not None:
                return DataLoader(
                    self.train_dataset,
                    batch_size=self.args.train_batch_size,
                    sampler=self.train_sampler,
                    num_workers=self.args.dataloader_num_workers,
                    pin_memory=self.args.dataloader_pin_memory,
                    collate_fn=self.data_collator # æ˜¾å¼ä¼ é€’ collator
                )
            return super().get_train_dataloader()

        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
            # è¿™é‡Œçš„ inputs åŒ…å« input_ids, attention_mask, labels
            if "labels" in inputs:
                labels = inputs.pop("labels")
            else:
                # å…¼å®¹ä¸åŒ transformer ç‰ˆæœ¬çš„å˜é‡å
                labels = inputs.get("label") 
            
            outputs = model(**inputs)
            logits = outputs.logits
            
            loss = self.loss_fn(logits, labels)
            return (loss, outputs) if return_outputs else loss

    # --- 9.5. è¯„ä¼°æŒ‡æ ‡å‡½æ•° ---
    def compute_metrics(eval_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼šaccuracy, precision, recall, f1"""
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)
        # é˜²æ­¢"å¡Œé™·åˆ°å•ä¸€ç±»åˆ«"æ—¶æŒ‡æ ‡è¡¨é¢ç¨³å®šï¼šè¾“å‡ºé¢„æµ‹ç±»åˆ«å¤šæ ·æ€§
        num_pred_classes = int(np.unique(preds).size)
        acc = accuracy_score(labels, preds)
        precision, recall, f1, _ = precision_recall_fscore_support(
            labels, preds, average='weighted', zero_division=0
        )
        return {
            'accuracy': acc,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'pred_classes': num_pred_classes
        }

    # --- 10. è®­ç»ƒå‚æ•°ä¸å¯åŠ¨ ---
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=16, # éªŒè¯é›†ä¸éœ€è¦åå‘ä¼ æ’­ï¼Œç¨å¾®å¤§ä¸€ç‚¹
        gradient_accumulation_steps=2,
        learning_rate=2e-5,
        weight_decay=0.01,
        warmup_ratio=0.06,
        lr_scheduler_type='cosine',
        fp16=torch.cuda.is_available(),
        logging_strategy='epoch',
        eval_strategy='epoch',
        save_strategy='epoch',
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model='f1',
        greater_is_better=True,
        report_to='none',
        seed=RANDOM_SEED,
        dataloader_num_workers=0, # Windowsä¸‹è®¾ä¸º0ï¼ŒLinuxå¯è®¾ä¸º4
        dataloader_pin_memory=True,
        remove_unused_columns=False # å…³é”®ï¼šé˜²æ­¢ Dataset ä¸­çš„è‡ªå®šä¹‰åˆ—è¢«è¿‡æ»¤
    )

    trainer = CustomLossTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[DetailedLoggingCallback(), EarlyStoppingCallback(early_stopping_patience=2)],
        loss_fn=loss_fn,
        train_sampler=train_sampler
    )

    # è®­ç»ƒå‰æ£€æŸ¥
    print("\nğŸ” è®­ç»ƒå‰æ£€æŸ¥ (Sanity Check)...")
    try:
        sample_input = {k: v.unsqueeze(0).to(device) for k, v in train_dataset[0].items() if k != 'labels'}
        with torch.no_grad():
            _ = model(**sample_input)
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        print("æç¤º: æ£€æŸ¥æ¨¡å‹è¯è¡¨å¤§å°ä¸ Tokenizer æ˜¯å¦åŒ¹é…ï¼Œæˆ–è€… labels æ˜¯å¦è¶Šç•Œã€‚")
        return

    # æ­£å¼è®­ç»ƒ
    trainer.train()
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ° {output_dir}...")
    trainer.save_model(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    # ä¿å­˜/å¤åˆ¶æ ‡ç­¾æ˜ å°„ï¼Œä¾›æ¨ç†/ç”Ÿæˆå™¨ä½¿ç”¨
    mapping_src = Path(PROCESSED_DATA_BASE_DIR) / dataset_name / 'bert' / mode / 'attack_type_mapping.json'
    mapping_dst = Path(output_dir) / 'attack_type_mapping.json'
    if mode == 'multiclass':
        if mapping_src.exists():
            try:
                shutil.copyfile(mapping_src, mapping_dst)
                print(f"å·²å¤åˆ¶å¤šåˆ†ç±»æ ‡ç­¾æ˜ å°„åˆ°: {mapping_dst}")
            except Exception as e:
                print(f"å¤åˆ¶æ ‡ç­¾æ˜ å°„å¤±è´¥: {e}")
        else:
            print(f"è­¦å‘Š: å¤šåˆ†ç±»æ¨¡å¼æœªæ‰¾åˆ° {mapping_src}ï¼Œä¸‹æ¸¸è‹¥éœ€è¦ç±»åˆ«åæ˜ å°„è¯·é‡æ–°è¿è¡Œé¢„å¤„ç†ç”Ÿæˆã€‚")
    else:
        # äºŒåˆ†ç±»ï¼šæ— è®ºæºæ˜ å°„æ˜¯å¦å­˜åœ¨ï¼Œéƒ½å†™å…¥æ˜ç¡®çš„äºŒåˆ†ç±»æ˜ å°„ï¼Œé¿å…è¯¯ç”¨å¤šåˆ†ç±»æ˜ å°„æ–‡ä»¶
        try:
            with open(mapping_dst, 'w', encoding='utf-8') as f:
                json.dump({"Normal": 0, "Attack": 1}, f, ensure_ascii=False, indent=2)
            print(f"å·²å†™å…¥äºŒåˆ†ç±»æ ‡ç­¾æ˜ å°„: {mapping_dst}")
        except Exception:
            pass
    
    # ä¿å­˜è®­ç»ƒä¿¡æ¯ï¼Œä¾› generator å‚è€ƒ
    training_info = {
        'num_labels': int(num_labels),
        'use_session_tokens': bool(use_session_tokens),
        'session_stat_features': session_stat_cols if use_session_tokens else [],
        'loss_type': loss_type
    }
    with open(os.path.join(output_dir, 'training_info.json'), 'w', encoding='utf-8') as f:
        json.dump(training_info, f, ensure_ascii=False, indent=2)
    
    # è¯¦ç»†è¯„ä¼°
    print("\n" + "="*80)
    print("æœ€ç»ˆè¯„ä¼°")
    print("="*80)
    
    def evaluate_detailed(dataset, labels, split_name):
        print(f"\n{split_name}é›†:")
        # ä½¿ç”¨ model.eval() æ¨¡å¼ç›´æ¥è¿›è¡Œé¢„æµ‹ï¼Œé¿å… trainer.predict æ‰“å°é¢å¤–ä¿¡æ¯
        model.eval()
        all_preds = []
        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)
        with torch.no_grad():
            for batch in dataloader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()
                all_preds.extend(preds)
        preds = np.array(all_preds)
        # æŒ‡å®š labels ç¡®ä¿å¤šåˆ†ç±»æ—¶æ‰€æœ‰ç±»åˆ«éƒ½å‡ºç°åœ¨æŠ¥å‘Šä¸­
        print(classification_report(labels, preds, labels=list(range(num_labels)), digits=4, zero_division=0))
        return preds
    
    train_preds = evaluate_detailed(train_dataset, train_labels, "è®­ç»ƒ")
    val_preds = evaluate_detailed(val_dataset, val_labels, "éªŒè¯")
    test_preds = evaluate_detailed(test_dataset, test_labels, "æµ‹è¯•")
    
    # è·å–æ—¥å¿—å›è°ƒå®ä¾‹
    logging_cb = None
    for cb in trainer.callback_handler.callbacks:
        if isinstance(cb, DetailedLoggingCallback):
            logging_cb = cb
            break
    
    # ç»˜å›¾ä¸æ··æ·†çŸ©é˜µ
    if logging_cb is not None:
        plot = logging_cb.get_plot_data()
        if len(plot['epochs']) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            axes[0, 0].plot(plot['epochs'], plot['train_losses'], 'b-o', label='Train')
            axes[0, 0].plot(plot['epochs'], plot['val_losses'], 'r-o', label='Val')
            axes[0, 0].set_xlabel('Epoch'); axes[0, 0].set_ylabel('Loss'); axes[0, 0].set_title('Loss Curves'); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].xaxis.set_major_locator(MaxNLocator(integer=True))
            axes[0, 1].plot(plot['epochs'], plot['val_accs'], 'g-o'); axes[0, 1].set_xlabel('Epoch'); axes[0, 1].set_ylabel('Accuracy'); axes[0, 1].set_title('Validation Accuracy'); axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].xaxis.set_major_locator(MaxNLocator(integer=True))
            axes[1, 0].plot(plot['epochs'], plot['val_f1s'], 'm-o'); axes[1, 0].set_xlabel('Epoch'); axes[1, 0].set_ylabel('F1 Score'); axes[1, 0].set_title('Validation F1'); axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].xaxis.set_major_locator(MaxNLocator(integer=True))
            cm = confusion_matrix(test_labels, test_preds)
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1], cbar=True)
            axes[1, 1].set_xlabel('Predicted'); axes[1, 1].set_ylabel('True'); axes[1, 1].set_title('Confusion Matrix (Test)')
            plt.tight_layout()
            plt.savefig(f"{output_dir}/training_curves.png", dpi=300, bbox_inches='tight')
            print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜: {output_dir}/training_curves.png")
            plt.close()
    
    # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
    def compute_split_metrics(labels, preds):
        acc = accuracy_score(labels, preds)
        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)
        return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}
    
    metrics = {
        'train': compute_split_metrics(train_labels, train_preds),
        'val': compute_split_metrics(val_labels, val_preds),
        'test': compute_split_metrics(test_labels, test_preds)
    }
    with open(f"{output_dir}/evaluation_metrics.json", 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜: {output_dir}/evaluation_metrics.json")
    
    print("\n" + "="*80)
    print("âœ“ è®­ç»ƒä¸è¯„ä¼°å…¨éƒ¨å®Œæˆ")
    print("="*80 + "\n")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', type=str, default=MODEL_PATH)
    parser.add_argument('--bert_dir', type=str, default=None,
                       help='æ•°æ®ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ® --mode è‡ªåŠ¨é€‰æ‹© processed_data/bert/binary æˆ– multiclassï¼‰')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ® --mode è‡ªåŠ¨é€‰æ‹© roberta-finetuned æˆ– roberta-finetuned-multiclassï¼‰')
    parser.add_argument('--epochs', type=int, default=NUM_EPOCHS)
    parser.add_argument('--mode', type=str, choices=['binary', 'multiclass'], default=DEFAULT_MODE,
                       help='è®­ç»ƒæ¨¡å¼: binary(äºŒåˆ†ç±») æˆ– multiclass(å¤šåˆ†ç±»)ï¼Œè‡ªåŠ¨é€‰æ‹©å¯¹åº”æ•°æ®ç›®å½•')
    parser.add_argument('--dataset', type=str, default=DEFAULT_DATASET,
                       help=f'æ•°æ®é›†åç§°ï¼ˆä¾‹å¦‚: NF-UNSW-NB15-v3ï¼‰ï¼Œé»˜è®¤: {DEFAULT_DATASET}')
    # æ§åˆ¶æ˜¯å¦åœ¨ BERT è¾“å…¥ä¸­æ‹¼æ¥ä¼šè¯å‰ç¼€ç‰¹å¾ä¼ª tokenï¼Œä¾¿äºåšæ¶ˆèå®éªŒ
    parser.add_argument('--use_session_tokens', dest='use_session_tokens', action='store_true')
    parser.add_argument('--no_session_tokens', dest='use_session_tokens', action='store_false')
    parser.set_defaults(use_session_tokens=True)
    # æŸå¤±å‡½æ•°é€‰æ‹©
    parser.add_argument('--loss_type', type=str, choices=['focal', 'focal_weighted', 'ce'],
                       default='focal',
                       help='æŸå¤±å‡½æ•°ç±»å‹: focal(æ— æƒé‡Focal Loss), focal_weighted(æœ‰æƒé‡Focal Loss), ce(çº¯äº¤å‰ç†µ)')
    args = parser.parse_args()

    # æ ¹æ® mode è‡ªåŠ¨é€‰æ‹©è¾“å‡ºç›®å½•ï¼ˆå¦‚æœç”¨æˆ·æœªæŒ‡å®šï¼‰
    output_dir = args.output_dir if args.output_dir else get_output_dir(args.mode)

    train_roberta(
        model_path=args.model_path,
        bert_dir=args.bert_dir,  # æ­¤å‚æ•°ç°åœ¨ä»…ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…ç”± dataset å’Œ mode å†³å®š
        output_dir=output_dir,
        num_epochs=args.epochs,
        mode=args.mode,
        dataset_name=args.dataset,
        use_session_tokens=args.use_session_tokens,
        loss_type=args.loss_type
    )