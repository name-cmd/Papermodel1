# -*- coding: utf-8 -*-
"""
æµé‡ç”Ÿæˆæ¨¡å‹è¯„ä¼°æ¨¡å— (Evaluation Module)

æœ¬æ¨¡å—æä¾›æµé‡ç”Ÿæˆè´¨é‡çš„ç»¼åˆè¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒï¼š
1. è¢«å…¶ä»–æ¨¡å— import è°ƒç”¨ï¼ˆè®­ç»ƒ/ç”Ÿæˆæ—¶å®æ—¶è®°å½•ï¼‰
2. ç‹¬ç«‹è¿è¡Œè¿›è¡Œæ‰¹é‡è¯„ä¼°å’ŒæŠ¥å‘Šç”Ÿæˆ

è¯„ä¼°æŒ‡æ ‡ï¼š
- å›°æƒ‘åº¦ (Perplexity): è¡¡é‡è¯­è¨€æ¨¡å‹å¯¹åºåˆ—çš„é¢„æµ‹èƒ½åŠ›
- JS æ•£åº¦ (Jensen-Shannon Divergence): è¡¡é‡ç”Ÿæˆæµé‡ä¸çœŸå®æµé‡çš„åˆ†å¸ƒå·®å¼‚
- ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity): è¡¡é‡åµŒå…¥ç©ºé—´ä¸­çš„è¯­ä¹‰ç›¸ä¼¼æ€§
- ç»Ÿè®¡ä¿çœŸåº¦: å‡å€¼/æ ‡å‡†å·®/åˆ†ä½æ•°çš„ç›¸å¯¹è¯¯å·®
- æœ‰æ•ˆæµæ¯”ä¾‹: ç”Ÿæˆæµé‡çš„ç»“æ„æœ‰æ•ˆæ€§

å‚è€ƒæ–‡çŒ®:
- Jensen-Shannon Divergence: Lin, J. (1991). Divergence measures based on the Shannon entropy.
- Perplexity: Jelinek et al. (1977). Perplexityâ€”a measure of the difficulty of speech recognition tasks.
"""

import os
import json
import math
import argparse
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from collections import defaultdict
from datetime import datetime
import warnings

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

# æ·±åº¦å­¦ä¹ 
import torch
import torch.nn.functional as F
from scipy.stats import entropy
from scipy.spatial.distance import cosine

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# è®¾ç½® matplotlib æ ·å¼
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.dpi'] = 150
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# ============================================================================
# 1. å›°æƒ‘åº¦è®¡ç®— (Perplexity)
# ============================================================================

def compute_perplexity(loss: float) -> float:
    """
    æ ¹æ®äº¤å‰ç†µæŸå¤±è®¡ç®—å›°æƒ‘åº¦ã€‚
    
    å›°æƒ‘åº¦å®šä¹‰: PPL = exp(CrossEntropyLoss)
    
    å‚æ•°:
        loss: äº¤å‰ç†µæŸå¤±å€¼
        
    è¿”å›:
        perplexity: å›°æƒ‘åº¦å€¼
        
    å‚è€ƒ:
        Jelinek et al. (1977). Perplexityâ€”a measure of the difficulty 
        of speech recognition tasks.
    """
    if loss < 0:
        warnings.warn(f"Loss å€¼ä¸ºè´Ÿ ({loss})ï¼Œå¯èƒ½å­˜åœ¨è®¡ç®—é”™è¯¯")
        return float('inf')
    
    try:
        perplexity = math.exp(loss)
    except OverflowError:
        perplexity = float('inf')
    
    return perplexity


def compute_sequence_perplexity(
    model, 
    tokenizer, 
    sequences: List[str],
    device: torch.device = None,
    batch_size: int = 8
) -> Tuple[float, List[float]]:
    """
    è®¡ç®—ä¸€ç»„åºåˆ—çš„å¹³å‡å›°æƒ‘åº¦ã€‚
    
    å‚æ•°:
        model: GPT-2 è¯­è¨€æ¨¡å‹
        tokenizer: å¯¹åº”çš„åˆ†è¯å™¨
        sequences: å¾…è¯„ä¼°çš„æ–‡æœ¬åºåˆ—åˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡
        batch_size: æ‰¹æ¬¡å¤§å°
        
    è¿”å›:
        avg_perplexity: å¹³å‡å›°æƒ‘åº¦
        per_sequence_ppl: æ¯ä¸ªåºåˆ—çš„å›°æƒ‘åº¦åˆ—è¡¨
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model.eval()
    model.to(device)
    
    per_sequence_ppl = []
    total_loss = 0.0
    total_tokens = 0
    
    with torch.no_grad():
        for i in range(0, len(sequences), batch_size):
            batch_seqs = sequences[i:i+batch_size]
            
            for seq in batch_seqs:
                inputs = tokenizer(
                    seq, 
                    return_tensors='pt', 
                    truncation=True, 
                    max_length=1024
                ).to(device)
                
                outputs = model(**inputs, labels=inputs['input_ids'])
                loss = outputs.loss.item()
                num_tokens = inputs['input_ids'].shape[1]
                
                ppl = compute_perplexity(loss)
                per_sequence_ppl.append(ppl)
                
                total_loss += loss * num_tokens
                total_tokens += num_tokens
    
    avg_loss = total_loss / total_tokens if total_tokens > 0 else float('inf')
    avg_perplexity = compute_perplexity(avg_loss)
    
    return avg_perplexity, per_sequence_ppl


# ============================================================================
# 2. JS æ•£åº¦è®¡ç®— (Jensen-Shannon Divergence)
# ============================================================================

def compute_histogram(
    values: np.ndarray, 
    bins: int = 50,
    range_minmax: Tuple[float, float] = None
) -> Tuple[np.ndarray, np.ndarray]:
    """
    è®¡ç®—æ•°å€¼çš„ç›´æ–¹å›¾åˆ†å¸ƒï¼ˆå½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼‰ã€‚
    
    å‚æ•°:
        values: æ•°å€¼æ•°ç»„
        bins: ç›´æ–¹å›¾ç®±æ•°
        range_minmax: å€¼åŸŸèŒƒå›´ (min, max)ï¼Œè‹¥ä¸º None åˆ™è‡ªåŠ¨è®¡ç®—
        
    è¿”å›:
        hist: å½’ä¸€åŒ–çš„æ¦‚ç‡åˆ†å¸ƒ
        bin_edges: ç®±è¾¹ç•Œ
    """
    values = np.array(values, dtype=np.float64)
    values = values[~np.isnan(values)]  # ç§»é™¤ NaN
    
    if len(values) == 0:
        return np.zeros(bins), np.linspace(0, 1, bins + 1)
    
    if range_minmax is None:
        range_minmax = (values.min(), values.max())
    
    # é˜²æ­¢ range ç›¸ç­‰
    if range_minmax[0] == range_minmax[1]:
        range_minmax = (range_minmax[0] - 0.5, range_minmax[1] + 0.5)
    
    hist, bin_edges = np.histogram(values, bins=bins, range=range_minmax, density=True)
    
    # å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼ˆç¡®ä¿å’Œä¸º1ï¼‰
    hist = hist / (hist.sum() + 1e-10)
    
    return hist, bin_edges


def compute_js_divergence(
    real_values: np.ndarray, 
    generated_values: np.ndarray,
    bins: int = 50
) -> float:
    """
    è®¡ç®— Jensen-Shannon æ•£åº¦ã€‚
    
    JS æ•£åº¦æ˜¯ KL æ•£åº¦çš„å¯¹ç§°ç‰ˆæœ¬ï¼Œå–å€¼èŒƒå›´ [0, 1]ï¼ˆä½¿ç”¨ log2 æ—¶ï¼‰ã€‚
    JS(P||Q) = 0.5 * KL(P||M) + 0.5 * KL(Q||M), å…¶ä¸­ M = 0.5 * (P + Q)
    
    å‚æ•°:
        real_values: çœŸå®æ•°æ®æ•°å€¼æ•°ç»„
        generated_values: ç”Ÿæˆæ•°æ®æ•°å€¼æ•°ç»„
        bins: ç›´æ–¹å›¾ç®±æ•°
        
    è¿”å›:
        js_divergence: JS æ•£åº¦å€¼ [0, 1]
        
    å‚è€ƒ:
        Lin, J. (1991). Divergence measures based on the Shannon entropy.
        IEEE Transactions on Information Theory, 37(1), 145-151.
    """
    real_values = np.array(real_values, dtype=np.float64)
    generated_values = np.array(generated_values, dtype=np.float64)
    
    # ç§»é™¤æ— æ•ˆå€¼
    real_values = real_values[~np.isnan(real_values) & ~np.isinf(real_values)]
    generated_values = generated_values[~np.isnan(generated_values) & ~np.isinf(generated_values)]
    
    if len(real_values) == 0 or len(generated_values) == 0:
        return 1.0  # æ— æ•°æ®æ—¶è¿”å›æœ€å¤§æ•£åº¦
    
    # ç»Ÿä¸€å€¼åŸŸèŒƒå›´
    all_values = np.concatenate([real_values, generated_values])
    range_minmax = (all_values.min(), all_values.max())
    
    # è®¡ç®—ç›´æ–¹å›¾
    p, _ = compute_histogram(real_values, bins=bins, range_minmax=range_minmax)
    q, _ = compute_histogram(generated_values, bins=bins, range_minmax=range_minmax)
    
    # æ·»åŠ å¹³æ»‘é¡¹é˜²æ­¢é™¤é›¶
    epsilon = 1e-10
    p = p + epsilon
    q = q + epsilon
    
    # é‡æ–°å½’ä¸€åŒ–
    p = p / p.sum()
    q = q / q.sum()
    
    # è®¡ç®—ä¸­é—´åˆ†å¸ƒ M
    m = 0.5 * (p + q)
    
    # è®¡ç®— JS æ•£åº¦ï¼ˆä½¿ç”¨ log2ï¼Œç»“æœåœ¨ [0, 1]ï¼‰
    js_div = 0.5 * entropy(p, m, base=2) + 0.5 * entropy(q, m, base=2)
    
    return float(js_div)


def compute_kl_divergence(
    real_values: np.ndarray, 
    generated_values: np.ndarray,
    bins: int = 50
) -> float:
    """
    è®¡ç®— KL æ•£åº¦ D_KL(P_real || P_generated)ã€‚
    
    æ³¨æ„: KL æ•£åº¦æ˜¯éå¯¹ç§°çš„ï¼Œè¿™é‡Œè®¡ç®—çš„æ˜¯çœŸå®åˆ†å¸ƒåˆ°ç”Ÿæˆåˆ†å¸ƒçš„ KL æ•£åº¦ã€‚
    
    å‚æ•°:
        real_values: çœŸå®æ•°æ®æ•°å€¼æ•°ç»„
        generated_values: ç”Ÿæˆæ•°æ®æ•°å€¼æ•°ç»„
        bins: ç›´æ–¹å›¾ç®±æ•°
        
    è¿”å›:
        kl_divergence: KL æ•£åº¦å€¼ [0, +âˆ)
    """
    real_values = np.array(real_values, dtype=np.float64)
    generated_values = np.array(generated_values, dtype=np.float64)
    
    real_values = real_values[~np.isnan(real_values) & ~np.isinf(real_values)]
    generated_values = generated_values[~np.isnan(generated_values) & ~np.isinf(generated_values)]
    
    if len(real_values) == 0 or len(generated_values) == 0:
        return float('inf')
    
    all_values = np.concatenate([real_values, generated_values])
    range_minmax = (all_values.min(), all_values.max())
    
    p, _ = compute_histogram(real_values, bins=bins, range_minmax=range_minmax)
    q, _ = compute_histogram(generated_values, bins=bins, range_minmax=range_minmax)
    
    epsilon = 1e-10
    p = p + epsilon
    q = q + epsilon
    p = p / p.sum()
    q = q / q.sum()
    
    kl_div = entropy(p, q, base=2)
    
    return float(kl_div)


# ============================================================================
# 3. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®— (Cosine Similarity)
# ============================================================================

def compute_cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
    
    Cosine Similarity = (A Â· B) / (||A|| * ||B||)
    
    å‚æ•°:
        vec1: å‘é‡1
        vec2: å‘é‡2
        
    è¿”å›:
        similarity: ä½™å¼¦ç›¸ä¼¼åº¦ [-1, 1]
    """
    vec1 = np.array(vec1, dtype=np.float64).flatten()
    vec2 = np.array(vec2, dtype=np.float64).flatten()
    
    if len(vec1) != len(vec2):
        raise ValueError(f"å‘é‡ç»´åº¦ä¸åŒ¹é…: {len(vec1)} vs {len(vec2)}")
    
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    similarity = 1.0 - cosine(vec1, vec2)  # scipy.cosine è¿”å›çš„æ˜¯è·ç¦»
    
    return float(similarity)


def compute_embedding_similarity(
    model,
    tokenizer,
    real_texts: List[str],
    generated_texts: List[str],
    device: torch.device = None,
    batch_size: int = 32
) -> Dict[str, float]:
    """
    ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è®¡ç®—çœŸå®æ–‡æœ¬å’Œç”Ÿæˆæ–‡æœ¬åœ¨åµŒå…¥ç©ºé—´ä¸­çš„ç›¸ä¼¼åº¦ã€‚
    
    æ–¹æ³•:
    1. æå–æ‰€æœ‰æ–‡æœ¬çš„ [CLS] æˆ–å¹³å‡æ± åŒ–åµŒå…¥
    2. è®¡ç®—çœŸå®æ–‡æœ¬åµŒå…¥çš„è´¨å¿ƒ
    3. è®¡ç®—ç”Ÿæˆæ–‡æœ¬åµŒå…¥çš„è´¨å¿ƒ
    4. è®¡ç®—è´¨å¿ƒé—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
    5. è®¡ç®—é€å¯¹ç›¸ä¼¼åº¦çš„ç»Ÿè®¡é‡
    
    å‚æ•°:
        model: é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ DistilBERTï¼‰
        tokenizer: å¯¹åº”çš„åˆ†è¯å™¨
        real_texts: çœŸå®æ–‡æœ¬åˆ—è¡¨
        generated_texts: ç”Ÿæˆæ–‡æœ¬åˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡
        batch_size: æ‰¹æ¬¡å¤§å°
        
    è¿”å›:
        åŒ…å«å¤šç§ç›¸ä¼¼åº¦æŒ‡æ ‡çš„å­—å…¸
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model.eval()
    model.to(device)
    
    def get_embeddings(texts: List[str]) -> np.ndarray:
        embeddings = []
        with torch.no_grad():
            for i in range(0, len(texts), batch_size):
                batch = texts[i:i+batch_size]
                inputs = tokenizer(
                    batch, 
                    return_tensors='pt', 
                    truncation=True, 
                    max_length=512,
                    padding=True
                ).to(device)
                
                outputs = model(**inputs, output_hidden_states=True)
                
                # ä½¿ç”¨æœ€åä¸€å±‚çš„ [CLS] token æˆ–å¹³å‡æ± åŒ–
                if hasattr(outputs, 'last_hidden_state'):
                    # å¹³å‡æ± åŒ–
                    hidden = outputs.last_hidden_state
                    mask = inputs['attention_mask'].unsqueeze(-1)
                    pooled = (hidden * mask).sum(1) / mask.sum(1)
                else:
                    # ä½¿ç”¨ pooler_output
                    pooled = outputs.pooler_output
                
                embeddings.append(pooled.cpu().numpy())
        
        return np.vstack(embeddings)
    
    # è·å–åµŒå…¥
    real_embeddings = get_embeddings(real_texts)
    gen_embeddings = get_embeddings(generated_texts)
    
    # è®¡ç®—è´¨å¿ƒ
    real_centroid = real_embeddings.mean(axis=0)
    gen_centroid = gen_embeddings.mean(axis=0)
    
    # è´¨å¿ƒä½™å¼¦ç›¸ä¼¼åº¦
    centroid_similarity = compute_cosine_similarity(real_centroid, gen_centroid)
    
    # è®¡ç®—æ‰€æœ‰çœŸå®æ ·æœ¬ä¸ç”Ÿæˆè´¨å¿ƒçš„ç›¸ä¼¼åº¦
    real_to_gen_centroid = [
        compute_cosine_similarity(emb, gen_centroid) 
        for emb in real_embeddings
    ]
    
    # è®¡ç®—æ‰€æœ‰ç”Ÿæˆæ ·æœ¬ä¸çœŸå®è´¨å¿ƒçš„ç›¸ä¼¼åº¦
    gen_to_real_centroid = [
        compute_cosine_similarity(emb, real_centroid) 
        for emb in gen_embeddings
    ]
    
    return {
        'centroid_cosine_similarity': centroid_similarity,
        'real_to_gen_centroid_mean': float(np.mean(real_to_gen_centroid)),
        'real_to_gen_centroid_std': float(np.std(real_to_gen_centroid)),
        'gen_to_real_centroid_mean': float(np.mean(gen_to_real_centroid)),
        'gen_to_real_centroid_std': float(np.std(gen_to_real_centroid)),
    }


# ============================================================================
# 4. ç»Ÿè®¡ä¿çœŸåº¦æŒ‡æ ‡ (Statistical Fidelity)
# ============================================================================

def compute_statistical_fidelity(
    real_values: np.ndarray, 
    generated_values: np.ndarray
) -> Dict[str, float]:
    """
    è®¡ç®—ç»Ÿè®¡ä¿çœŸåº¦æŒ‡æ ‡ã€‚
    
    åŒ…æ‹¬:
    - å‡å€¼ç›¸å¯¹è¯¯å·® (Mean Relative Error)
    - æ ‡å‡†å·®ç›¸å¯¹è¯¯å·® (Std Relative Error)
    - å„åˆ†ä½æ•°çš„ç›¸å¯¹è¯¯å·® (Quantile Relative Errors)
    
    å‚æ•°:
        real_values: çœŸå®æ•°æ®æ•°å€¼æ•°ç»„
        generated_values: ç”Ÿæˆæ•°æ®æ•°å€¼æ•°ç»„
        
    è¿”å›:
        åŒ…å«å„ç»Ÿè®¡æŒ‡æ ‡ç›¸å¯¹è¯¯å·®çš„å­—å…¸
    """
    real_values = np.array(real_values, dtype=np.float64)
    generated_values = np.array(generated_values, dtype=np.float64)
    
    real_values = real_values[~np.isnan(real_values) & ~np.isinf(real_values)]
    generated_values = generated_values[~np.isnan(generated_values) & ~np.isinf(generated_values)]
    
    if len(real_values) == 0 or len(generated_values) == 0:
        return {
            'mean_relative_error': float('inf'),
            'std_relative_error': float('inf'),
            'median_relative_error': float('inf'),
            'q25_relative_error': float('inf'),
            'q75_relative_error': float('inf'),
            'q99_relative_error': float('inf'),
        }
    
    def relative_error(real_val, gen_val):
        if abs(real_val) < 1e-10:
            return abs(gen_val - real_val)
        return abs(gen_val - real_val) / abs(real_val)
    
    # åŸºæœ¬ç»Ÿè®¡é‡
    real_mean = np.mean(real_values)
    gen_mean = np.mean(generated_values)
    real_std = np.std(real_values)
    gen_std = np.std(generated_values)
    
    # åˆ†ä½æ•°
    quantiles = [0.25, 0.5, 0.75, 0.99]
    real_quantiles = np.quantile(real_values, quantiles)
    gen_quantiles = np.quantile(generated_values, quantiles)
    
    return {
        'real_mean': float(real_mean),
        'generated_mean': float(gen_mean),
        'mean_relative_error': relative_error(real_mean, gen_mean),
        'real_std': float(real_std),
        'generated_std': float(gen_std),
        'std_relative_error': relative_error(real_std, gen_std),
        'q25_relative_error': relative_error(real_quantiles[0], gen_quantiles[0]),
        'median_relative_error': relative_error(real_quantiles[1], gen_quantiles[1]),
        'q75_relative_error': relative_error(real_quantiles[2], gen_quantiles[2]),
        'q99_relative_error': relative_error(real_quantiles[3], gen_quantiles[3]),
    }


# ============================================================================
# 5. æœ‰æ•ˆæµæ¯”ä¾‹ (Valid Flow Ratio)
# ============================================================================

def compute_valid_flow_ratio(
    generated_flows: List[str],
    expected_field_count: int,
    tolerance: float = 0.3
) -> Dict[str, float]:
    """
    è®¡ç®—ç”Ÿæˆæµé‡çš„ç»“æ„æœ‰æ•ˆæ€§ã€‚
    
    æœ‰æ•ˆæ€§åˆ¤æ–­æ ‡å‡†:
    1. å­—æ®µæ•°é‡åœ¨é¢„æœŸèŒƒå›´å†…
    2. æ•°å€¼å­—æ®µå¯è§£æ
    
    å‚æ•°:
        generated_flows: ç”Ÿæˆçš„æµæ–‡æœ¬åˆ—è¡¨
        expected_field_count: é¢„æœŸçš„å­—æ®µæ•°é‡
        tolerance: å­—æ®µæ•°é‡å®¹å·®æ¯”ä¾‹
        
    è¿”å›:
        åŒ…å«æœ‰æ•ˆæ€§ç»Ÿè®¡çš„å­—å…¸
    """
    if not generated_flows:
        return {
            'total_flows': 0,
            'valid_flows': 0,
            'valid_ratio': 0.0,
            'avg_field_count': 0.0,
            'field_count_std': 0.0,
        }
    
    valid_count = 0
    field_counts = []
    
    min_fields = int(expected_field_count * (1 - tolerance))
    max_fields = int(expected_field_count * (1 + tolerance))
    
    for flow in generated_flows:
        fields = flow.strip().split()
        field_count = len(fields)
        field_counts.append(field_count)
        
        # æ£€æŸ¥å­—æ®µæ•°é‡
        if min_fields <= field_count <= max_fields:
            # æ£€æŸ¥æ•°å€¼å¯è§£ææ€§
            parseable = True
            for field in fields:
                try:
                    float(field)
                except ValueError:
                    # å…è®¸æŸäº›éæ•°å€¼å­—æ®µ
                    if field not in ['<bos>', '<eos>', '<pad>']:
                        parseable = False
                        break
            
            if parseable:
                valid_count += 1
    
    return {
        'total_flows': len(generated_flows),
        'valid_flows': valid_count,
        'valid_ratio': valid_count / len(generated_flows),
        'avg_field_count': float(np.mean(field_counts)),
        'field_count_std': float(np.std(field_counts)),
        'expected_field_count': expected_field_count,
    }


# ============================================================================
# 6. ç»¼åˆè¯„ä¼°æŠ¥å‘Šç±»
# ============================================================================

class EvaluationReport:
    """
    ç»¼åˆè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨ã€‚
    
    ç”¨äºæ”¶é›†ã€æ±‡æ€»å’Œå¯¼å‡ºæ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ã€‚
    """
    
    def __init__(self, output_dir: str = './evaluation_results'):
        """
        åˆå§‹åŒ–è¯„ä¼°æŠ¥å‘Šã€‚
        
        å‚æ•°:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.metrics = {
            'meta': {
                'timestamp': datetime.now().isoformat(),
                'random_seed': RANDOM_SEED,
            },
            'perplexity': {},
            'js_divergence': {},
            'kl_divergence': {},
            'cosine_similarity': {},
            'statistical_fidelity': {},
            'validity': {},
        }
        
        self.feature_distributions = {}
    
    def add_perplexity(self, name: str, value: float, details: Dict = None):
        """æ·»åŠ å›°æƒ‘åº¦æŒ‡æ ‡"""
        self.metrics['perplexity'][name] = {
            'value': value,
            'details': details or {}
        }
    
    def add_divergence(
        self, 
        feature_name: str, 
        real_values: np.ndarray, 
        generated_values: np.ndarray,
        bins: int = 50
    ):
        """è®¡ç®—å¹¶æ·»åŠ æ•£åº¦æŒ‡æ ‡"""
        js_div = compute_js_divergence(real_values, generated_values, bins)
        kl_div = compute_kl_divergence(real_values, generated_values, bins)
        stat_fidelity = compute_statistical_fidelity(real_values, generated_values)
        
        self.metrics['js_divergence'][feature_name] = js_div
        self.metrics['kl_divergence'][feature_name] = kl_div
        self.metrics['statistical_fidelity'][feature_name] = stat_fidelity
        
        # ä¿å­˜åˆ†å¸ƒæ•°æ®ç”¨äºç»˜å›¾
        self.feature_distributions[feature_name] = {
            'real': real_values,
            'generated': generated_values,
        }
    
    def add_cosine_similarity(self, metrics: Dict[str, float]):
        """æ·»åŠ ä½™å¼¦ç›¸ä¼¼åº¦æŒ‡æ ‡"""
        self.metrics['cosine_similarity'] = metrics
    
    def add_validity(self, metrics: Dict[str, float]):
        """æ·»åŠ æœ‰æ•ˆæ€§æŒ‡æ ‡"""
        self.metrics['validity'] = metrics
    
    def compute_summary(self) -> Dict[str, float]:
        """è®¡ç®—æ±‡æ€»æŒ‡æ ‡"""
        summary = {}
        
        # å¹³å‡ JS æ•£åº¦
        js_values = list(self.metrics['js_divergence'].values())
        if js_values:
            summary['avg_js_divergence'] = float(np.mean(js_values))
            summary['max_js_divergence'] = float(np.max(js_values))
            summary['min_js_divergence'] = float(np.min(js_values))
        
        # å¹³å‡ç»Ÿè®¡è¯¯å·®
        stat_errors = []
        for feat, stats in self.metrics['statistical_fidelity'].items():
            if 'mean_relative_error' in stats:
                stat_errors.append(stats['mean_relative_error'])
        if stat_errors:
            summary['avg_mean_relative_error'] = float(np.mean(stat_errors))
        
        # æœ‰æ•ˆç‡
        if self.metrics['validity']:
            summary['valid_ratio'] = self.metrics['validity'].get('valid_ratio', 0.0)
        
        # è´¨å¿ƒä½™å¼¦ç›¸ä¼¼åº¦
        if self.metrics['cosine_similarity']:
            summary['centroid_cosine_similarity'] = self.metrics['cosine_similarity'].get(
                'centroid_cosine_similarity', 0.0
            )
        
        self.metrics['summary'] = summary
        return summary
    
    def save_report(self, filename: str = 'evaluation_report.json'):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Šä¸º JSON æ–‡ä»¶"""
        self.compute_summary()
        
        # å°† numpy ç±»å‹è½¬æ¢ä¸º Python åŸç”Ÿç±»å‹
        def convert_to_serializable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.int64, np.int32)):
                return int(obj)
            elif isinstance(obj, (np.float64, np.float32)):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(v) for v in obj]
            return obj
        
        serializable_metrics = convert_to_serializable(self.metrics)
        
        report_path = os.path.join(self.output_dir, filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_metrics, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        return report_path
    
    def plot_distributions(self, n_cols: int = 3, n_rows: int = 5):
        """
        ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•° (CDF) å¯¹æ¯”å›¾ã€‚
        ä¸ä½¿ç”¨åˆ†ç®± (Binning)ï¼Œç›´æ¥åŸºäºåŸå§‹æ•°æ®ç»˜åˆ¶ï¼Œä»¥å±•ç¤ºæ›´ç²¾ç»†çš„åˆ†å¸ƒå·®å¼‚ã€‚
        
        å‚æ•°:
            n_cols: æ¯è¡Œçš„å­å›¾æ•°é‡ï¼Œé»˜è®¤ä¸º 3
            n_rows: æ€»è¡Œæ•°ï¼Œé»˜è®¤ä¸º 5ï¼ˆå…±ç»˜åˆ¶ 15 ä¸ªç‰¹å¾ï¼‰
        """
        if not self.feature_distributions:
            print("âš ï¸ æ— åˆ†å¸ƒæ•°æ®å¯ç»˜åˆ¶")
            return
        
        # æŒ‰ JS æ•£åº¦æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰ï¼Œè·å–æ‰€æœ‰ç‰¹å¾
        sorted_features = sorted(
            self.metrics['js_divergence'].items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        n_features = len(sorted_features)
        total_slots = n_cols * n_rows
        
        # å¦‚æœç‰¹å¾æ•°é‡è¶…è¿‡é¢„è®¾çš„ 5x3=15 ä¸ªï¼Œè‡ªåŠ¨æ‰©å±•è¡Œæ•°
        if n_features > total_slots:
            n_rows = (n_features + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))
        if n_features == 1:
            axes = np.array([axes])
        axes = axes.flatten()
        
        for idx, (feature_name, js_div) in enumerate(sorted_features):
            if idx >= len(axes):
                break
            ax = axes[idx]
            
            real_data = np.sort(self.feature_distributions[feature_name]['real'])
            gen_data = np.sort(self.feature_distributions[feature_name]['generated'])
            
            # è®¡ç®— CDF
            real_y = np.arange(1, len(real_data) + 1) / len(real_data)
            gen_y = np.arange(1, len(gen_data) + 1) / len(gen_data)
            
            # ç»˜åˆ¶ CDF
            ax.plot(real_data, real_y, label='Real', color='blue', linewidth=2)
            ax.plot(gen_data, gen_y, label='Generated', color='darkorange', linewidth=2, linestyle='--')
            
            ax.set_title(f'{feature_name}\nJS Divergence: {js_div:.4f}')
            ax.set_xlabel('Value')
            ax.set_ylabel('CDF')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(n_features, len(axes)):
            axes[idx].set_visible(False)
        
        plt.suptitle('Feature CDF Comparison (Real vs Generated)', 
                     fontsize=14, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        plot_path = os.path.join(self.output_dir, 'distribution_comparison.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… åˆ†å¸ƒå¯¹æ¯”å›¾ (CDF) å·²ä¿å­˜è‡³: {plot_path}")
        return plot_path
    
    def plot_divergence_heatmap(self):
        """ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„æ•£åº¦çƒ­åŠ›å›¾"""
        if not self.metrics['js_divergence']:
            print("âš ï¸ æ— æ•£åº¦æ•°æ®å¯ç»˜åˆ¶")
            return
        
        features = list(self.metrics['js_divergence'].keys())
        js_values = [self.metrics['js_divergence'][f] for f in features]
        
        # åˆ›å»ºæ•°æ®æ¡†
        df = pd.DataFrame({
            'Feature': features,
            'JS Divergence': js_values
        })
        df = df.sort_values('JS Divergence', ascending=True)
        
        # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
        fig, ax = plt.subplots(figsize=(10, max(6, len(features) * 0.4)))
        
        colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(features)))
        bars = ax.barh(df['Feature'], df['JS Divergence'], color=colors)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, val in zip(bars, df['JS Divergence']):
            ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                   f'{val:.4f}', va='center', fontsize=9)
        
        ax.set_xlabel('JS Divergence')
        ax.set_title('Jensen-Shannon Divergence by Feature\n(Lower is Better)', 
                    fontsize=12, fontweight='bold')
        ax.set_xlim(0, max(js_values) * 1.2)
        ax.grid(True, alpha=0.3, axis='x')
        
        plt.tight_layout()
        
        plot_path = os.path.join(self.output_dir, 'divergence_summary.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… æ•£åº¦æ±‡æ€»å›¾å·²ä¿å­˜è‡³: {plot_path}")
        return plot_path
    
    def export_distributions_to_csv(self):
        """
        å°†ç‰¹å¾åˆ†å¸ƒæ•°æ®å¯¼å‡ºä¸º CSV æ–‡ä»¶ï¼Œä¾› Origin ç­‰ç»‘å›¾è½¯ä»¶ä½¿ç”¨ã€‚
        
        å¯¼å‡ºä¸‰ä¸ªæ–‡ä»¶ï¼š
        1. distribution_raw_data.csv: æ¯ä¸ªç‰¹å¾çš„åŸå§‹æ•°å€¼ï¼ˆReal å’Œ Generatedï¼‰
        2. distribution_histogram.csv: æ¯ä¸ªç‰¹å¾çš„ç›´æ–¹å›¾åˆ†ç®±æ•°æ®
        3. distribution_summary.csv: å„ç‰¹å¾çš„æ•£åº¦å’Œç»Ÿè®¡æ±‡æ€»
        """
        if not self.feature_distributions:
            print("âš ï¸ æ— åˆ†å¸ƒæ•°æ®å¯å¯¼å‡º")
            return
        
        # === 1. å¯¼å‡ºåŸå§‹æ•°æ® ===
        raw_data_path = os.path.join(self.output_dir, 'distribution_raw_data.csv')
        
        # æ‰¾åˆ°æœ€å¤§é•¿åº¦
        max_len = 0
        for fname, data in self.feature_distributions.items():
            max_len = max(max_len, len(data['real']), len(data['generated']))
        
        # æ„å»º DataFrame
        raw_df_dict = {}
        for fname, data in self.feature_distributions.items():
            real_vals = list(data['real']) + [np.nan] * (max_len - len(data['real']))
            gen_vals = list(data['generated']) + [np.nan] * (max_len - len(data['generated']))
            raw_df_dict[f'{fname}_Real'] = real_vals
            raw_df_dict[f'{fname}_Generated'] = gen_vals
        
        raw_df = pd.DataFrame(raw_df_dict)
        raw_df.to_csv(raw_data_path, index=False, encoding='utf-8-sig')
        print(f"âœ… åŸå§‹åˆ†å¸ƒæ•°æ®å·²å¯¼å‡º: {raw_data_path}")
        
        # === 2. (å·²ç§»é™¤) å¯¼å‡ºç›´æ–¹å›¾æ•°æ® ===
        # æ ¹æ®ç”¨æˆ·è¦æ±‚ç§»é™¤åˆ†ç®±æ“ä½œ
        hist_data_path = None
        
        # === 3. å¯¼å‡ºæ±‡æ€»ç»Ÿè®¡è¡¨ ===
        summary_path = os.path.join(self.output_dir, 'distribution_summary.csv')
        
        summary_records = []
        for fname in self.feature_distributions.keys():
            js_div = self.metrics['js_divergence'].get(fname, np.nan)
            kl_div = self.metrics['kl_divergence'].get(fname, np.nan)
            stat = self.metrics['statistical_fidelity'].get(fname, {})
            
            summary_records.append({
                'Feature': fname,
                'JS_Divergence': js_div,
                'KL_Divergence': kl_div,
                'Real_Mean': stat.get('real_mean', np.nan),
                'Generated_Mean': stat.get('generated_mean', np.nan),
                'Mean_Relative_Error': stat.get('mean_relative_error', np.nan),
                'Real_Std': stat.get('real_std', np.nan),
                'Generated_Std': stat.get('generated_std', np.nan),
                'Std_Relative_Error': stat.get('std_relative_error', np.nan),
                'Q25_Relative_Error': stat.get('q25_relative_error', np.nan),
                'Median_Relative_Error': stat.get('median_relative_error', np.nan),
                'Q75_Relative_Error': stat.get('q75_relative_error', np.nan),
                'Q99_Relative_Error': stat.get('q99_relative_error', np.nan),
            })
        
        summary_df = pd.DataFrame(summary_records)
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        print(f"âœ… æ±‡æ€»ç»Ÿè®¡è¡¨å·²å¯¼å‡º: {summary_path}")
        
        return raw_data_path, None, summary_path

    def print_summary(self):
        """æ‰“å°è¯„ä¼°æ‘˜è¦"""
        summary = self.compute_summary()
        
        print("\n" + "=" * 60)
        print(" " * 18 + "è¯„ä¼°ç»“æœæ‘˜è¦")
        print("=" * 60)
        
        # å›°æƒ‘åº¦
        if self.metrics['perplexity']:
            print("\nğŸ“Š å›°æƒ‘åº¦ (Perplexity):")
            for name, data in self.metrics['perplexity'].items():
                print(f"   {name}: {data['value']:.4f}")
        
        # JS æ•£åº¦
        if self.metrics['js_divergence']:
            js_values = list(self.metrics['js_divergence'].values())
            print(f"\nğŸ“Š JS æ•£åº¦ (Jensen-Shannon Divergence):")
            print(f"   å¹³å‡: {np.mean(js_values):.4f}")
            print(f"   æœ€å¤§: {np.max(js_values):.4f} ({max(self.metrics['js_divergence'], key=self.metrics['js_divergence'].get)})")
            print(f"   æœ€å°: {np.min(js_values):.4f} ({min(self.metrics['js_divergence'], key=self.metrics['js_divergence'].get)})")
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        if self.metrics['cosine_similarity']:
            print(f"\nğŸ“Š ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity):")
            cs = self.metrics['cosine_similarity']
            if 'centroid_cosine_similarity' in cs:
                print(f"   è´¨å¿ƒç›¸ä¼¼åº¦: {cs['centroid_cosine_similarity']:.4f}")
            if 'gen_to_real_centroid_mean' in cs:
                print(f"   ç”Ÿæˆâ†’çœŸå®è´¨å¿ƒ: {cs['gen_to_real_centroid_mean']:.4f} Â± {cs['gen_to_real_centroid_std']:.4f}")
        
        # æœ‰æ•ˆæ€§
        if self.metrics['validity']:
            v = self.metrics['validity']
            print(f"\nğŸ“Š æœ‰æ•ˆæ€§ (Validity):")
            print(f"   æœ‰æ•ˆæµæ¯”ä¾‹: {v.get('valid_ratio', 0):.2%} ({v.get('valid_flows', 0)}/{v.get('total_flows', 0)})")
            print(f"   å¹³å‡å­—æ®µæ•°: {v.get('avg_field_count', 0):.1f} (é¢„æœŸ: {v.get('expected_field_count', 0)})")
        
        print("\n" + "=" * 60)


# ============================================================================
# 7. æµé‡è§£æå·¥å…·å‡½æ•°
# ============================================================================

def parse_flow_file(
    file_path: str,
    feature_names: List[str] = None
) -> Tuple[List[str], Dict[str, List[float]]]:
    """
    è§£ææµé‡æ–‡ä»¶ï¼Œæå–æµæ–‡æœ¬å’Œç‰¹å¾å€¼ã€‚
    
    å‚æ•°:
        file_path: æµé‡æ–‡ä»¶è·¯å¾„
        feature_names: ç‰¹å¾ååˆ—è¡¨
        
    è¿”å›:
        flows: æµæ–‡æœ¬åˆ—è¡¨
        features: {ç‰¹å¾å: æ•°å€¼åˆ—è¡¨} å­—å…¸
    """
    flows = []
    features = defaultdict(list)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line in ['<bos>', '<eos>']:
                continue
            if line.startswith('['):  # è·³è¿‡æ³¨é‡Šè¡Œ
                continue
            
            flows.append(line)
            
            # è§£æç‰¹å¾å€¼
            if feature_names:
                fields = line.split()
                for i, fname in enumerate(feature_names):
                    if i < len(fields):
                        try:
                            features[fname].append(float(fields[i]))
                        except ValueError:
                            pass
    
    # è½¬æ¢ä¸º numpy æ•°ç»„
    features = {k: np.array(v) for k, v in features.items()}
    
    return flows, features


def parse_generated_output(
    file_path: str,
    feature_names: List[str] = None
) -> Tuple[List[str], Dict[str, List[float]]]:
    """
    è§£æç”Ÿæˆå™¨è¾“å‡ºæ–‡ä»¶ã€‚
    
    å‚æ•°:
        file_path: ç”Ÿæˆç»“æœæ–‡ä»¶è·¯å¾„
        feature_names: ç‰¹å¾ååˆ—è¡¨
        
    è¿”å›:
        flows: ç”Ÿæˆçš„æµæ–‡æœ¬åˆ—è¡¨
        features: {ç‰¹å¾å: æ•°å€¼åˆ—è¡¨} å­—å…¸
    """
    flows = []
    features = defaultdict(list)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œã€ä¼šè¯å¤´ã€æ³¨é‡Š
            if not line:
                continue
            if line.startswith('=') or line.startswith('[') or line.startswith('Session'):
                continue
            if '<bos>' in line or '<eos>' in line:
                continue
            
            # è¿™æ˜¯ä¸€æ¡æµè®°å½•
            flows.append(line)
            
            if feature_names:
                fields = line.split()
                for i, fname in enumerate(feature_names):
                    if i < len(fields):
                        try:
                            features[fname].append(float(fields[i]))
                        except ValueError:
                            pass
    
    features = {k: np.array(v) for k, v in features.items()}
    
    return flows, features


# ============================================================================
# 8. ä¸»å‡½æ•°ï¼šç‹¬ç«‹è¿è¡Œæ¨¡å¼
# ============================================================================

# ============================================================================
# é…ç½®å¸¸é‡ï¼ˆä¸ generator.py / distilbert_training.py ä¿æŒä¸€è‡´ï¼‰
# ============================================================================
DEFAULT_DATASET = 'NF-UNSW-NB15-v3'  # é»˜è®¤æ•°æ®é›†åç§°
PROCESSED_DATA_BASE_DIR = './processed_data'  # é¢„å¤„ç†æ•°æ®åŸºç¡€ç›®å½•
GENERATED_DATA_DIR = './generated_data'  # ç”Ÿæˆæ•°æ®ç›®å½•
DEFAULT_BERT_MODEL_PATH = './models/distilbert-finetuned'  # DistilBERT æ¨¡å‹è·¯å¾„


def main():
    """ç‹¬ç«‹è¿è¡Œè¯„ä¼°æ¨¡å—"""
    parser = argparse.ArgumentParser(description='æµé‡ç”Ÿæˆè´¨é‡è¯„ä¼°æ¨¡å—')
    parser.add_argument('--dataset', type=str, default=DEFAULT_DATASET,
                       help=f'æ•°æ®é›†åç§°ï¼ˆä¾‹å¦‚: NF-UNSW-NB15-v3ï¼‰ï¼Œé»˜è®¤: {DEFAULT_DATASET}')
    parser.add_argument('--real_data', type=str, default=None,
                       help='çœŸå®æµé‡æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ®æ•°æ®é›†è‡ªåŠ¨æ¨æ–­: ./processed_data/{dataset}/test_gpt2_input.txtï¼‰')
    parser.add_argument('--generated_data', type=str, default=None,
                       help='ç”Ÿæˆæµé‡æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ®æ•°æ®é›†è‡ªåŠ¨æ¨æ–­: ./generated_data/generated_flows_only_{dataset}.txtï¼‰')
    parser.add_argument('--feature_config', type=str, default=None,
                       help='ç‰¹å¾é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ®æ•°æ®é›†è‡ªåŠ¨æ¨æ–­: ./processed_data/{dataset}/feature_columns.jsonï¼‰')
    parser.add_argument('--output_dir', type=str, default='./evaluation_results',
                       help='è¯„ä¼°ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--bert_model', type=str, default=None,
                       help=f'DistilBERT æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼‰ï¼Œé»˜è®¤: {DEFAULT_BERT_MODEL_PATH}')
    parser.add_argument('--skip_cosine', action='store_true',
                       help='è·³è¿‡ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆèŠ‚çœæ—¶é—´ï¼‰')
    
    args = parser.parse_args()
    
    # è·å–æ•°æ®é›†åç§°
    dataset_name = args.dataset
    
    print("\n" + "=" * 60)
    print(" " * 15 + "æµé‡ç”Ÿæˆè´¨é‡è¯„ä¼°")
    print("=" * 60)
    print(f"æ•°æ®é›†: {dataset_name}")
    
    # æ ¹æ®æ•°æ®é›†åç§°è‡ªåŠ¨æ¨æ–­è·¯å¾„ï¼ˆä¸ generator.py / distilbert_training.py ä¸€è‡´ï¼‰
    dataset_dir = os.path.join(PROCESSED_DATA_BASE_DIR, dataset_name)
    
    # ç‰¹å¾é…ç½®æ–‡ä»¶è·¯å¾„
    if args.feature_config:
        feature_config_path = args.feature_config
    else:
        feature_config_path = os.path.join(dataset_dir, 'feature_columns.json')
    
    # çœŸå®æ•°æ®æ–‡ä»¶è·¯å¾„
    if args.real_data:
        real_data_path = args.real_data
    else:
        real_data_path = os.path.join(dataset_dir, 'test_gpt2_input.txt')
    
    # ç”Ÿæˆæ•°æ®æ–‡ä»¶è·¯å¾„
    if args.generated_data:
        generated_data_path = args.generated_data
    else:
        generated_data_path = os.path.join(GENERATED_DATA_DIR, f'generated_flows_only_{dataset_name}.txt')
    
    # DistilBERT æ¨¡å‹è·¯å¾„
    bert_model_path = args.bert_model if args.bert_model else DEFAULT_BERT_MODEL_PATH
    
    # åŠ è½½ç‰¹å¾é…ç½®
    print("\nğŸ“ åŠ è½½é…ç½®...")
    print(f"   ç‰¹å¾é…ç½®æ–‡ä»¶: {feature_config_path}")
    if not os.path.exists(feature_config_path):
        print(f"âŒ ç‰¹å¾é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {feature_config_path}")
        print(f"   æç¤º: è¯·ç¡®è®¤æ•°æ®é›† '{dataset_name}' å·²å®Œæˆé¢„å¤„ç†ï¼Œ")
        print(f"         æˆ–ä½¿ç”¨ --feature_config å‚æ•°æŒ‡å®šç‰¹å¾é…ç½®æ–‡ä»¶è·¯å¾„")
        return
    
    with open(feature_config_path, 'r', encoding='utf-8') as f:
        feature_cfg = json.load(f)
    
    feature_names = feature_cfg.get('flow_text_features', [])
    print(f"   ç‰¹å¾æ•°é‡: {len(feature_names)}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {feature_names}")
    
    # è§£æçœŸå®æ•°æ®
    print(f"\nğŸ“ è§£æçœŸå®æ•°æ®: {real_data_path}")
    if not os.path.exists(real_data_path):
        print(f"âŒ çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {real_data_path}")
        print(f"   æç¤º: è¯·ç¡®è®¤æ•°æ®é›† '{dataset_name}' å·²å®Œæˆé¢„å¤„ç†ï¼Œ")
        print(f"         æˆ–ä½¿ç”¨ --real_data å‚æ•°æŒ‡å®šçœŸå®æ•°æ®æ–‡ä»¶è·¯å¾„")
        return
    
    real_flows, real_features = parse_flow_file(real_data_path, feature_names)
    print(f"   è§£ææµæ•°é‡: {len(real_flows)}")
    
    # è§£æç”Ÿæˆæ•°æ®
    print(f"\nğŸ“ è§£æç”Ÿæˆæ•°æ®: {generated_data_path}")
    if not os.path.exists(generated_data_path):
        print(f"âŒ ç”Ÿæˆæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {generated_data_path}")
        print(f"   æç¤º: è¯·å…ˆè¿è¡Œ generator.py ç”Ÿæˆæµé‡æ•°æ®ï¼Œ")
        print(f"         æˆ–ä½¿ç”¨ --generated_data å‚æ•°æŒ‡å®šç”Ÿæˆæ•°æ®æ–‡ä»¶è·¯å¾„")
        return
    
    gen_flows, gen_features = parse_generated_output(generated_data_path, feature_names)
    print(f"   è§£ææµæ•°é‡: {len(gen_flows)}")
    
    if len(gen_flows) == 0:
        print("âŒ æœªè§£æåˆ°ä»»ä½•ç”Ÿæˆæµé‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        return
    
    # åˆ›å»ºè¯„ä¼°æŠ¥å‘Š
    report = EvaluationReport(output_dir=args.output_dir)
    
    # è®¡ç®—å„ç‰¹å¾çš„æ•£åº¦
    print("\nğŸ“Š è®¡ç®—åˆ†å¸ƒæ•£åº¦...")
    for fname in feature_names:
        if fname in real_features and fname in gen_features:
            if len(real_features[fname]) > 0 and len(gen_features[fname]) > 0:
                report.add_divergence(fname, real_features[fname], gen_features[fname])
                print(f"   {fname}: JS={report.metrics['js_divergence'][fname]:.4f}")
    
    # è®¡ç®—æœ‰æ•ˆæ€§
    print("\nğŸ“Š è®¡ç®—æœ‰æ•ˆæ€§...")
    validity = compute_valid_flow_ratio(gen_flows, len(feature_names))
    report.add_validity(validity)
    print(f"   æœ‰æ•ˆæµæ¯”ä¾‹: {validity['valid_ratio']:.2%}")
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå¯é€‰ï¼‰
    if not args.skip_cosine and os.path.exists(bert_model_path):
        print("\nğŸ“Š è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦...")
        try:
            from transformers import AutoTokenizer, AutoModel
            
            tokenizer = AutoTokenizer.from_pretrained(bert_model_path)
            model = AutoModel.from_pretrained(bert_model_path)
            
            # é‡‡æ ·ä»¥åŠ é€Ÿï¼ˆå¦‚æœæ•°æ®é‡å¤ªå¤§ï¼‰
            sample_size = min(500, len(real_flows), len(gen_flows))
            sampled_real = np.random.choice(real_flows, sample_size, replace=False).tolist()
            sampled_gen = np.random.choice(gen_flows, sample_size, replace=False).tolist()
            
            cos_metrics = compute_embedding_similarity(
                model, tokenizer, sampled_real, sampled_gen
            )
            report.add_cosine_similarity(cos_metrics)
            print(f"   è´¨å¿ƒä½™å¼¦ç›¸ä¼¼åº¦: {cos_metrics['centroid_cosine_similarity']:.4f}")
        except Exception as e:
            print(f"   âš ï¸ ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
    else:
        if args.skip_cosine:
            print("\nâ­ï¸ è·³è¿‡ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—")
        else:
            print(f"\nâš ï¸ DistilBERT æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³è¿‡ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—: {bert_model_path}")
    
    # ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
    print("\nğŸ“Š ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    report.save_report()
    report.plot_distributions()
    report.plot_divergence_heatmap()
    
    # å¯¼å‡º CSV æ•°æ®ä¾› Origin ç­‰ç»˜å›¾è½¯ä»¶ä½¿ç”¨
    print("\nğŸ“Š å¯¼å‡º CSV æ•°æ®...")
    report.export_distributions_to_csv()
    
    report.print_summary()
    
    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    print(f"   - distribution_raw_data.csv: åŸå§‹æ•°æ®ï¼ˆä¾› Origin ç»˜åˆ¶åˆ†å¸ƒæ›²çº¿ï¼‰")
    # print(f"   - distribution_histogram.csv: ç›´æ–¹å›¾æ•°æ®ï¼ˆå·²ç§»é™¤ï¼‰")
    print(f"   - distribution_summary.csv: æ•£åº¦æ±‡æ€»è¡¨")


if __name__ == "__main__":
    main()

